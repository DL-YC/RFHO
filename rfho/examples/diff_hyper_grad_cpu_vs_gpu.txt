Differences of hypergradient computations between forward and backward-HG

# run on all_methods_on_mnist.py (_check_all_methods) revision number 0ef7498c1ebbb20da00598e49baad0b421a4d948

#### CPU execution #####
(there are basically no differences here...)

# first run

SAVE DICT:
step: 0
mode: forward
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 22.57827553215
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980854]
rho_l1_1: [0.0, 10.473064]
rho_l1_2: [0.0, 33.517784]
rho_l2_0: [0.0, 1.2106586]
rho_l2_1: [0.0, 1.4387809]
rho_l2_2: [0.0, 0.48373219]
eta: [0.010999993, -39.794144]
mu: [0.50099999, -0.76688409]
Elapsed time (sec): 49

SAVE DICT:
step: 0
mode: reverse
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 255.88374289122
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980883]
rho_l1_1: [0.0, 10.473075]
rho_l1_2: [0.0, 33.517853]
rho_l2_0: [0.0, 1.2106622]
rho_l2_1: [0.0, 1.4387833]
rho_l2_2: [0.0, 0.48373321]
eta: [0.010999993, -39.794281]
mu: [0.50099999, -0.76688707]
Elapsed time (sec): 15




# second run....

step: 0
mode: forward
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 22.57827553215
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980854]
rho_l1_1: [0.0, 10.473064]
rho_l1_2: [0.0, 33.517784]
rho_l2_0: [0.0, 1.2106586]
rho_l2_1: [0.0, 1.4387809]
rho_l2_2: [0.0, 0.48373219]
eta: [0.010999993, -39.794144]
mu: [0.50099999, -0.76688409]
Elapsed time (sec): 47

SAVE DICT:
step: 0
mode: reverse
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 255.88374289122
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980883]
rho_l1_1: [0.0, 10.473075]
rho_l1_2: [0.0, 33.517853]
rho_l2_0: [0.0, 1.2106622]
rho_l2_1: [0.0, 1.4387833]
rho_l2_2: [0.0, 0.48373321]
eta: [0.010999993, -39.794281]
mu: [0.50099999, -0.76688707]
Elapsed time (sec): 15


# third run.... 
with hyperparameter optimization




SAVE DICT:
step: 0
mode: forward
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 22.57827553215
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980854]
rho_l1_1: [0.0, 10.473064]
rho_l1_2: [0.0, 33.517784]
rho_l2_0: [0.0, 1.2106586]
rho_l2_1: [0.0, 1.4387809]
rho_l2_2: [0.0, 0.48373219]
eta: [0.010999993, -39.794144]
mu: [0.50099999, -0.76688409]
Elapsed time (sec): 46

SAVE DICT:
step: 1
mode: forward
test accuracy: 0.556
validation accuracy: 0.561238
training accuracy: 0.545
validation error: 2.08558
memory usage (mb): 22.57827553215
weights: [ 0.00110424 -0.01956838 -0.04185919 ...,  0.01046236 -0.01378959
  0.00010357]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.590072]
rho_l1_1: [0.0, 10.83959]
rho_l1_2: [0.0, 34.790379]
rho_l2_0: [0.0, 1.2212617]
rho_l2_1: [0.0, 1.4819916]
rho_l2_2: [0.0, 0.49600434]
eta: [0.011994326, -34.834724]
mu: [0.50199884, -0.73887223]
Elapsed time (sec): 84

SAVE DICT:
step: 2
mode: forward
test accuracy: 0.600214
validation accuracy: 0.595857
training accuracy: 0.505
validation error: 2.04999
memory usage (mb): 22.57827553215
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.0177014  -0.01881725
  0.0042787 ]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 13.679873]
rho_l1_1: [0.0, 14.836711]
rho_l1_2: [0.0, 41.68634]
rho_l2_0: [0.0, 1.5119481]
rho_l2_1: [0.0, 1.9328388]
rho_l2_2: [0.0, 0.6364314]
eta: [0.012992319, -39.32436]
mu: [0.50300086, -0.90952623]
Elapsed time (sec): 122


  reverse

SAVE DICT:
step: 0
mode: reverse
test accuracy: 0.636214
validation accuracy: 0.633857
training accuracy: 0.55
validation error: 2.06643
memory usage (mb): 255.88374289122
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01338695 -0.01207654
  0.00042103]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.980883]
rho_l1_1: [0.0, 10.473075]
rho_l1_2: [0.0, 33.517853]
rho_l2_0: [0.0, 1.2106622]
rho_l2_1: [0.0, 1.4387833]
rho_l2_2: [0.0, 0.48373321]
eta: [0.010999993, -39.794281]
mu: [0.50099999, -0.76688707]
Elapsed time (sec): 15

SAVE DICT:
step: 1
mode: reverse
test accuracy: 0.556
validation accuracy: 0.561238
training accuracy: 0.545
validation error: 2.08558
memory usage (mb): 255.88374289122
weights: [ 0.00110424 -0.01956838 -0.04185919 ...,  0.01046236 -0.01378959
  0.00010357]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.590105]
rho_l1_1: [0.0, 10.839594]
rho_l1_2: [0.0, 34.789242]
rho_l2_0: [0.0, 1.2212667]
rho_l2_1: [0.0, 1.4819945]
rho_l2_2: [0.0, 0.49600551]
eta: [0.011994326, -34.834846]
mu: [0.50199884, -0.73887497]
Elapsed time (sec): 29

SAVE DICT:
step: 2
mode: reverse
test accuracy: 0.600214
validation accuracy: 0.595857
training accuracy: 0.505
validation error: 2.04999
memory usage (mb): 255.88374289122
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.0177014  -0.01881725
  0.0042787 ]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 13.679888]
rho_l1_1: [0.0, 14.836729]
rho_l1_2: [0.0, 41.68644]
rho_l2_0: [0.0, 1.5119534]
rho_l2_1: [0.0, 1.932842]
rho_l2_2: [0.0, 0.63643342]
eta: [0.012992319, -39.324543]
mu: [0.50300086, -0.90953016]
Elapsed time (sec): 42


#### GPU execution #####
GeForce GTX TITAN X

# first execution (with hyperparameter optimization)

step: 0
mode: forward
test accuracy: 0.627429
validation accuracy: 0.629142
training accuracy: 0.555
validation error: 2.07414
memory usage (mb): 22.57827553215
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.0133718  -0.01329451
  0.00094827]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.786844]
rho_l1_1: [0.0, 10.270536]
rho_l1_2: [0.0, 33.329597]
rho_l2_0: [0.0, 1.1789333]
rho_l2_1: [0.0, 1.4010124]
rho_l2_2: [0.0, 0.46996772]
eta: [0.011000023, -38.618832]
mu: [0.50099999, -0.74416441]
Elapsed time (sec): 17

SAVE DICT:
step: 1
mode: forward
test accuracy: 0.556643
validation accuracy: 0.558381
training accuracy: 0.535
validation error: 2.08244
memory usage (mb): 22.57827553215
weights: [  1.10423565e-03  -1.95683837e-02  -4.18591872e-02 ...,   1.02230692e-02
  -1.46698989e-02  -2.98847735e-05]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 12.01494]
rho_l1_1: [0.0, 11.15778]
rho_l1_2: [0.0, 34.683418]
rho_l2_0: [0.0, 1.2366766]
rho_l2_1: [0.0, 1.5013]
rho_l2_2: [0.0, 0.50242966]
eta: [0.011996618, -35.253078]
mu: [0.50200009, -0.74778789]
Elapsed time (sec): 24

SAVE DICT:
step: 2
mode: forward
test accuracy: 0.589571
validation accuracy: 0.588904
training accuracy: 0.53
validation error: 2.0454
memory usage (mb): 22.57827553215
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.017264   -0.02104477
  0.00213395]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 14.068892]
rho_l1_1: [0.0, 14.948112]
rho_l1_2: [0.0, 42.463928]
rho_l2_0: [0.0, 1.5519283]
rho_l2_1: [0.0, 1.9625192]
rho_l2_2: [0.0, 0.64862907]
eta: [0.012996569, -39.870949]
mu: [0.50300258, -0.92248023]
Elapsed time (sec): 31

    reverse

step: 0
mode: reverse
test accuracy: 0.627429
validation accuracy: 0.629142
training accuracy: 0.555
validation error: 2.07414
memory usage (mb): 255.88374289122
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01337181 -0.01329451
  0.00094827]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.786846]
rho_l1_1: [0.0, 10.270537]
rho_l1_2: [0.0, 33.329613]
rho_l2_0: [0.0, 1.1789334]
rho_l2_1: [0.0, 1.4010122]
rho_l2_2: [0.0, 0.46996772]
eta: [0.011000023, -38.618839]
mu: [0.50099999, -0.74416453]
Elapsed time (sec): 5

SAVE DICT:
step: 1
mode: reverse
test accuracy: 0.556643
validation accuracy: 0.558381
training accuracy: 0.535
validation error: 2.08244
memory usage (mb): 255.88374289122
weights: [  1.10423565e-03  -1.95683837e-02  -4.18591872e-02 ...,   1.02230692e-02
  -1.46698998e-02  -2.98859377e-05]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 12.014944]
rho_l1_1: [0.0, 11.157784]
rho_l1_2: [0.0, 34.683422]
rho_l2_0: [0.0, 1.2366763]
rho_l2_1: [0.0, 1.5012997]
rho_l2_2: [0.0, 0.50242978]
eta: [0.011996618, -35.253078]
mu: [0.50200009, -0.74778783]
Elapsed time (sec): 8

SAVE DICT:
step: 2
mode: reverse
test accuracy: 0.589071
validation accuracy: 0.587761
training accuracy: 0.53
validation error: 2.04489
memory usage (mb): 255.88374289122
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.01729583 -0.02102494
  0.00219355]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 14.072577]
rho_l1_1: [0.0, 14.967683]
rho_l1_2: [0.0, 42.451225]
rho_l2_0: [0.0, 1.5533755]
rho_l2_1: [0.0, 1.9654132]
rho_l2_2: [0.0, 0.64951634]
eta: [0.012996607, -39.947102]
mu: [0.50300252, -0.92422652]
Elapsed time (sec): 10

# second execution

step: 0
mode: forward
test accuracy: 0.627429
validation accuracy: 0.629142
training accuracy: 0.555
validation error: 2.07414
memory usage (mb): 22.57827553215
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01337181 -0.01329451
  0.00094827]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.786843]
rho_l1_1: [0.0, 10.270537]
rho_l1_2: [0.0, 33.32959]
rho_l2_0: [0.0, 1.1789331]
rho_l2_1: [0.0, 1.4010125]
rho_l2_2: [0.0, 0.46996769]
eta: [0.011000023, -38.618835]
mu: [0.50099999, -0.74416435]
Elapsed time (sec): 17

SAVE DICT:
step: 1
mode: forward
test accuracy: 0.556643
validation accuracy: 0.558381
training accuracy: 0.535
validation error: 2.08244
memory usage (mb): 22.57827553215
weights: [  1.10423565e-03  -1.95683837e-02  -4.18591872e-02 ...,   1.02230683e-02
  -1.46698998e-02  -2.98859522e-05]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 12.014939]
rho_l1_1: [0.0, 11.157779]
rho_l1_2: [0.0, 34.683418]
rho_l2_0: [0.0, 1.2366765]
rho_l2_1: [0.0, 1.5012997]
rho_l2_2: [0.0, 0.50242966]
eta: [0.011996619, -35.253078]
mu: [0.50200009, -0.74778789]
Elapsed time (sec): 24

SAVE DICT:
step: 2
mode: forward
test accuracy: 0.589072
validation accuracy: 0.587761
training accuracy: 0.53
validation error: 2.04489
memory usage (mb): 22.57827553215
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.01729583 -0.02102495
  0.00219355]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 14.072575]
rho_l1_1: [0.0, 14.967689]
rho_l1_2: [0.0, 42.451202]
rho_l2_0: [0.0, 1.5533756]
rho_l2_1: [0.0, 1.9654131]
rho_l2_2: [0.0, 0.6495167]
eta: [0.012996607, -39.947102]
mu: [0.50300252, -0.92422688]
Elapsed time (sec): 31


    reverse

SAVE DICT:
step: 0
mode: reverse
test accuracy: 0.627429
validation accuracy: 0.629142
training accuracy: 0.555
validation error: 2.07414
memory usage (mb): 255.88374289122
weights: [-0.01705388 -0.02053495 -0.00783848 ...,  0.01337181 -0.0132945
  0.00094827]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 11.786845]
rho_l1_1: [0.0, 10.270537]
rho_l1_2: [0.0, 33.329617]
rho_l2_0: [0.0, 1.1789335]
rho_l2_1: [0.0, 1.4010122]
rho_l2_2: [0.0, 0.46996772]
eta: [0.011000023, -38.618835]
mu: [0.50099999, -0.74416453]
Elapsed time (sec): 4

SAVE DICT:
step: 1
mode: reverse
test accuracy: 0.556643
validation accuracy: 0.558381
training accuracy: 0.535
validation error: 2.08244
memory usage (mb): 255.88374289122
weights: [  1.10423565e-03  -1.95683837e-02  -4.18591872e-02 ...,   1.02230692e-02
  -1.46698998e-02  -2.98862287e-05]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 12.014944]
rho_l1_1: [0.0, 11.157784]
rho_l1_2: [0.0, 34.683422]
rho_l2_0: [0.0, 1.2366763]
rho_l2_1: [0.0, 1.5012999]
rho_l2_2: [0.0, 0.50242978]
eta: [0.011996618, -35.253075]
mu: [0.50200009, -0.74778759]
Elapsed time (sec): 7

SAVE DICT:
step: 2
mode: reverse
test accuracy: 0.589072
validation accuracy: 0.587761
training accuracy: 0.53
validation error: 2.04489
memory usage (mb): 255.88374289122
weights: [-0.05886209  0.01617052  0.00187904 ...,  0.01729583 -0.02102495
  0.00219355]
# weights: 328810
# hyperparameters: 8
# iterations: 100
rho_l1_0: [0.0, 14.072576]
rho_l1_1: [0.0, 14.967683]
rho_l1_2: [0.0, 42.451225]
rho_l2_0: [0.0, 1.5533754]
rho_l2_1: [0.0, 1.9654132]
rho_l2_2: [0.0, 0.6495164]
eta: [0.012996607, -39.947105]
mu: [0.50300252, -0.92422646]
Elapsed time (sec): 10
